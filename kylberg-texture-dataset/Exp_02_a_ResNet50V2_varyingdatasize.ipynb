{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "smXRCRKE3gGt",
        "Bu99OidX-urG",
        "diZek2peqqfk"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP66ELjKbiKHyUW3AXhqbTz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunfflur/frequency-learning/blob/master/kylberg-texture-dataset/Exp_02_a_ResNet50V2_varyingdatasize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet50V2"
      ],
      "metadata": {
        "id": "p7l7rPShHiWE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smXRCRKE3gGt"
      },
      "source": [
        "#### Libraries Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oot4s_fB3W5F",
        "outputId": "b5b0bd28-281d-41ed-e942-17deb20acd05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-recommenders\n",
            "  Downloading tensorflow_recommenders-0.7.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-recommenders) (1.4.0)\n",
            "Requirement already satisfied: tensorflow>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-recommenders) (2.12.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.12.2)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.12.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.16.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (67.7.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.12.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.20.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.32.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.4.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (23.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.22.4)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (3.8.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.54.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (4.5.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (23.3.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.9.0->tensorflow-recommenders) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.9.0->tensorflow-recommenders) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.9.0->tensorflow-recommenders) (1.10.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (0.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (3.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (2.3.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (2.17.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (1.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.9.0->tensorflow-recommenders) (3.2.2)\n",
            "Installing collected packages: tensorflow-recommenders\n",
            "Successfully installed tensorflow-recommenders-0.7.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "s = 23\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(s)\n",
        "import random\n",
        "random.seed(s)\n",
        "from numpy.random import seed\n",
        "seed(s)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(s)\n",
        "\n",
        "import PIL\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense, Conv1D, Dropout, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "\n",
        "!pip install tensorflow-addons \n",
        "!pip install tensorflow-recommenders\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_recommenders as tfrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n0D9z1XL5xV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573bd1e0-3cbc-46e7-a4b4-892e7b8ce2ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May  3 01:09:00 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    50W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tk7Kjs6Mmsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b755985-2238-4355-e686-71ccc11154e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Drive mount"
      ],
      "metadata": {
        "id": "Bu99OidX-urG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TESSSSSST ###\n",
        "\n",
        "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!sudo apt-get update -qq 2>&1 > /dev/null\n",
        "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "!google-drive-ocamlfuse"
      ],
      "metadata": {
        "id": "je242-LYOKFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6acc762e-48e8-4632-99a6-47e41346fee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "/usr/bin/xdg-open: 869: www-browser: not found\n",
            "/usr/bin/xdg-open: 869: links2: not found\n",
            "/usr/bin/xdg-open: 869: elinks: not found\n",
            "/usr/bin/xdg-open: 869: links: not found\n",
            "/usr/bin/xdg-open: 869: lynx: not found\n",
            "/usr/bin/xdg-open: 869: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=ofS2DqD2MmW2Ca5k9bPRmsqZHVnsLG-S6xEn4ynlc0M'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/bin/sh: 1: open: not found\n",
            "Cannot retrieve auth tokens.\n",
            "Failure(\"Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=ofS2DqD2MmW2Ca5k9bPRmsqZHVnsLG-S6xEn4ynlc0M\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -qq w3m # to act as web browser \n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBjc7IqP3wqU",
        "outputId": "252a202d-bc31-4b2a-e68d-417225fc94c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package w3m.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 122523 files and directories currently installed.)\n",
            "Preparing to unpack .../w3m_0.5.3-37ubuntu0.1_amd64.deb ...\n",
            "Unpacking w3m (0.5.3-37ubuntu0.1) ...\n",
            "Setting up w3m (0.5.3-37ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "/content\n",
            "/content/drive\n",
            "/content\n",
            "/\n",
            "Access token retrieved correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Load"
      ],
      "metadata": {
        "id": "M_s5caaLiTaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### data loading ### \n",
        "path_train = '/content/drive/MyDrive/Mestrado/Datasets/kylberg-dataset/kylberg_train.npy'\n",
        "path_ytrain = '/content/drive/MyDrive/Mestrado/Datasets/kylberg-dataset/kylberg_y_train.npy'\n",
        "path_test = '/content/drive/MyDrive/Mestrado/Datasets/kylberg-dataset/kylberg_test.npy'\n",
        "path_ytest = '/content/drive/MyDrive/Mestrado/Datasets/kylberg-dataset/kylberg_y_test.npy'\n",
        "\n",
        "x_train, x_test = np.load(path_train), np.load(path_test)\n",
        "y_train, y_test = np.load(path_ytrain), np.load(path_ytest)\n",
        "x_train, x_test = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1), x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
        "\n",
        "# adjust dimension and change from array to tensor + convert to 3 channel images\n",
        "new_shape = (224,224)\n",
        "x_train, x_test = tf.image.resize(x_train, new_shape), tf.image.resize(x_test, new_shape)\n",
        "x_train, x_test = tf.image.grayscale_to_rgb(x_train), tf.image.grayscale_to_rgb(x_test)\n",
        "y_train, y_test = tf.stack(to_categorical(y_train)), tf.stack(to_categorical(y_test))"
      ],
      "metadata": {
        "id": "sKlHUxwXiWsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZocSwqbndUob",
        "outputId": "6b28789b-d50b-4a6f-9920-57fc74ec9797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3360, 224, 224, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pre-trained model"
      ],
      "metadata": {
        "id": "diZek2peqqfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the image for the ResNet50 model\n",
        "x_train1 = preprocess_input(x_train)\n",
        "x_test1 = preprocess_input(x_test)"
      ],
      "metadata": {
        "id": "1tuXuOwMqqfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_trained_model(input_shape, n_classes, optimizer, fine_tune=0):\n",
        "    \"\"\"\n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training.\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze. \n",
        "               0 = all pretrained layers will freeze during training\n",
        "    \"\"\"\n",
        "    \n",
        "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
        "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
        "    resnet50_model = ResNet50V2(include_top=True,\n",
        "                     weights='imagenet', \n",
        "                     input_shape=input_shape)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
        "    # depending on the size of the fine-tuning parameter.\n",
        "    \n",
        "    if fine_tune > 0:\n",
        "        for layer in resnet50_model.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in resnet50_model.layers:\n",
        "            layer.trainable = False\n",
        "    '''\n",
        "    for layer in resnet50_model.layers:\n",
        "      layer.trainable = True\n",
        "    '''\n",
        "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
        "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
        "    top_model = resnet50_model.layers[-2].output\n",
        "    #top_model = Flatten(name=\"flatten\")(top_model)\n",
        "    #top_model = Dense(4096, activation='relu')(top_model)\n",
        "    #top_model = Dense(128, activation='relu')(top_model)\n",
        "    #top_model = Dropout(0.25)(top_model)\n",
        "    output_layer = Dense(n_classes, activation='softmax', name='my_predictions')(top_model)\n",
        "    \n",
        "    # Group the convolutional base and new output into a Model object.\n",
        "    model = Model(inputs=resnet50_model.input, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "YsqMBc5cqqfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(s) #s\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "ResNet50_model = pre_trained_model(input_shape=(224,224,3), n_classes=28, optimizer=opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbN83ZFYqqfm",
        "outputId": "8ad754a3-1dd5-42b0-b48a-d8be68f8799c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102869336/102869336 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ResNet50_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6059304-ac2d-4c3c-c749-9eb3d063a4ce",
        "id": "6SC6PFJuqqfm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
            "                                                                  'conv2_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 28, 28, 256)  0           ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'conv2_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
            "                                                                  'conv3_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_1[0][0]',        \n",
            "                                                                  'conv3_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
            "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_2[0][0]',        \n",
            "                                                                  'conv4_block6_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
            "                                                                  'conv5_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['post_relu[0][0]']              \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " my_predictions (Dense)         (None, 28)           57372       ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,622,172\n",
            "Trainable params: 57,372\n",
            "Non-trainable params: 23,564,800\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ModelCheckpoint callback - save best weights\n",
        "estopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
        "checkpoint = ModelCheckpoint(filepath='/content/drive/MyDrive/Mestrado/Experimentos/exp2-KTD/exp2-pynb/model_resnet50v2_pt.weights.best.hdf5', save_best_only=True, verbose=0)\n",
        "history = ResNet50_model.fit(x_train1, y_train, epochs=100, batch_size=16, verbose=1, shuffle=True, validation_split=0.1, callbacks=[checkpoint, estopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa2a21d-72eb-4649-ed8f-54f21e90673c",
        "id": "EPcivYkNqqfn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "189/189 [==============================] - 26s 82ms/step - loss: 2.5088 - accuracy: 0.3770 - val_loss: 1.4942 - val_accuracy: 0.7976\n",
            "Epoch 2/100\n",
            "189/189 [==============================] - 13s 67ms/step - loss: 1.0123 - accuracy: 0.9130 - val_loss: 0.7226 - val_accuracy: 0.9851\n",
            "Epoch 3/100\n",
            "189/189 [==============================] - 13s 67ms/step - loss: 0.5459 - accuracy: 0.9769 - val_loss: 0.4416 - val_accuracy: 0.9970\n",
            "Epoch 4/100\n",
            "189/189 [==============================] - 13s 67ms/step - loss: 0.3613 - accuracy: 0.9854 - val_loss: 0.3080 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "189/189 [==============================] - 13s 67ms/step - loss: 0.2649 - accuracy: 0.9901 - val_loss: 0.2311 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "189/189 [==============================] - 13s 70ms/step - loss: 0.2064 - accuracy: 0.9914 - val_loss: 0.1812 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.1670 - accuracy: 0.9921 - val_loss: 0.1469 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "189/189 [==============================] - 13s 71ms/step - loss: 0.1390 - accuracy: 0.9937 - val_loss: 0.1223 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.1183 - accuracy: 0.9944 - val_loss: 0.1038 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.1022 - accuracy: 0.9944 - val_loss: 0.0892 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "189/189 [==============================] - 14s 72ms/step - loss: 0.0895 - accuracy: 0.9947 - val_loss: 0.0779 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0791 - accuracy: 0.9954 - val_loss: 0.0684 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0705 - accuracy: 0.9957 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0633 - accuracy: 0.9960 - val_loss: 0.0542 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0572 - accuracy: 0.9960 - val_loss: 0.0491 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "189/189 [==============================] - 14s 72ms/step - loss: 0.0519 - accuracy: 0.9967 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0474 - accuracy: 0.9967 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0434 - accuracy: 0.9970 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "189/189 [==============================] - 13s 67ms/step - loss: 0.0399 - accuracy: 0.9977 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "189/189 [==============================] - 13s 67ms/step - loss: 0.0367 - accuracy: 0.9977 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "189/189 [==============================] - 14s 72ms/step - loss: 0.0340 - accuracy: 0.9977 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0315 - accuracy: 0.9977 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0292 - accuracy: 0.9983 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0271 - accuracy: 0.9987 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "189/189 [==============================] - 13s 67ms/step - loss: 0.0253 - accuracy: 0.9983 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "189/189 [==============================] - 13s 71ms/step - loss: 0.0236 - accuracy: 0.9987 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0221 - accuracy: 0.9987 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0207 - accuracy: 0.9987 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0194 - accuracy: 0.9987 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0182 - accuracy: 0.9987 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "189/189 [==============================] - 13s 70ms/step - loss: 0.0171 - accuracy: 0.9987 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "189/189 [==============================] - 13s 70ms/step - loss: 0.0160 - accuracy: 0.9987 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0152 - accuracy: 0.9987 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0142 - accuracy: 0.9990 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0134 - accuracy: 0.9987 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "189/189 [==============================] - 13s 70ms/step - loss: 0.0127 - accuracy: 0.9990 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0120 - accuracy: 0.9990 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "189/189 [==============================] - 14s 72ms/step - loss: 0.0113 - accuracy: 0.9997 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0107 - accuracy: 0.9993 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0102 - accuracy: 0.9997 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "189/189 [==============================] - 13s 70ms/step - loss: 0.0096 - accuracy: 0.9993 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0091 - accuracy: 0.9993 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0087 - accuracy: 0.9997 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "189/189 [==============================] - 13s 67ms/step - loss: 0.0082 - accuracy: 0.9997 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0078 - accuracy: 0.9997 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0074 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "189/189 [==============================] - 13s 71ms/step - loss: 0.0071 - accuracy: 0.9997 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "189/189 [==============================] - 13s 71ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "189/189 [==============================] - 14s 73ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "189/189 [==============================] - 13s 67ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "189/189 [==============================] - 14s 72ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "189/189 [==============================] - 13s 67ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "189/189 [==============================] - 13s 71ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "189/189 [==============================] - 13s 70ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "189/189 [==============================] - 10s 53ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "189/189 [==============================] - 13s 70ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "189/189 [==============================] - 14s 73ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "189/189 [==============================] - 10s 53ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "189/189 [==============================] - 10s 53ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "189/189 [==============================] - 10s 53ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "189/189 [==============================] - 13s 70ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "189/189 [==============================] - 10s 53ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "189/189 [==============================] - 13s 70ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "189/189 [==============================] - 13s 68ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "189/189 [==============================] - 10s 53ms/step - loss: 9.9381e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "189/189 [==============================] - 10s 53ms/step - loss: 9.5925e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "189/189 [==============================] - 13s 70ms/step - loss: 9.2172e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "189/189 [==============================] - 10s 53ms/step - loss: 8.8807e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "189/189 [==============================] - 10s 53ms/step - loss: 8.6247e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "189/189 [==============================] - 13s 70ms/step - loss: 8.2958e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "189/189 [==============================] - 13s 69ms/step - loss: 7.9592e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "189/189 [==============================] - 10s 53ms/step - loss: 7.7108e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(121), plt.plot(history.history['loss'], label='loss')\n",
        "plt.subplot(121), plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Época', fontsize=12), plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Evolução da curva de perda')\n",
        "plt.legend()\n",
        "plt.subplot(122), plt.plot(history.history['accuracy'], label = 'accuracy', color='green')\n",
        "plt.subplot(122), plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Época', fontsize=12), plt.ylabel('Acc', fontsize=12)\n",
        "plt.title('Evolução da curva de acurácia')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "95b8c034-7012-47f3-ed36-84327b65ac8d",
        "id": "DyCVyXA3qqfn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet50_model.load_weights('/content/drive/MyDrive/Mestrado/Experimentos/exp8 - ALOT/exp8-pynb/model_resnet50v2_pt.weights.best.hdf5')"
      ],
      "metadata": {
        "id": "C_i4RZJAqqfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TEST ACC ###\n",
        "scores = ResNet50_model.evaluate(x_test1, y_test)\n",
        "print('\\n%s : %.2f%%' % (ResNet50_model.metrics_names[1], scores[1] * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb9c1340-5fb9-4f38-f948-bf287c71b06c",
        "id": "NPINWeH1qqfn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 5s 88ms/step - loss: 0.0042 - accuracy: 0.9991\n",
            "\n",
            "accuracy : 99.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Initialization"
      ],
      "metadata": {
        "id": "DJORaKeEjcUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the image for the ResNet50 model\n",
        "x_train1 = preprocess_input(x_train)\n",
        "x_test1 = preprocess_input(x_test)\n",
        "del x_train\n",
        "del x_test"
      ],
      "metadata": {
        "id": "jrOzWD1ttKAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def non_pre_trained_model(input_shape, n_classes, optimizer, fine_tune=0):\n",
        "    \"\"\"\n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training.\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze. \n",
        "               0 = all pretrained layers will freeze during training\n",
        "    \"\"\"\n",
        "    \n",
        "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
        "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
        "    resnet50_model = ResNet50V2(include_top=True,\n",
        "                     weights=None, \n",
        "                     input_shape=input_shape)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
        "    # depending on the size of the fine-tuning parameter.\n",
        "    '''\n",
        "    if fine_tune > 0:\n",
        "        for layer in resnet50_model.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in resnet50_model.layers:\n",
        "            layer.trainable = False\n",
        "    '''\n",
        "    for layer in resnet50_model.layers:\n",
        "      layer.trainable = True\n",
        "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
        "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
        "    top_model = resnet50_model.layers[-2].output\n",
        "    #top_model = Flatten(name=\"flatten\")(top_model)\n",
        "    #top_model = Dense(4096, activation='relu')(top_model)\n",
        "    #top_model = Dense(128, activation='relu')(top_model)\n",
        "    #top_model = Dropout(0.25)(top_model)\n",
        "    output_layer = Dense(n_classes, activation='softmax', name='my_predictions')(top_model)\n",
        "    \n",
        "    # Group the convolutional base and new output into a Model object.\n",
        "    model = Model(inputs=resnet50_model.input, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "7RwEJmvLjdz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(s) #s\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "ResNet50_model = non_pre_trained_model(input_shape=(224,224,3), n_classes=28, optimizer=opt)"
      ],
      "metadata": {
        "id": "LqpIuR1tw3yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ResNet50_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpyjW7_mQBET",
        "outputId": "15f8089f-8a97-4038-a924-c440203187e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
            "                                                                  'conv2_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 28, 28, 256)  0           ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'conv2_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
            "                                                                  'conv3_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_1[0][0]',        \n",
            "                                                                  'conv3_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
            "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_2[0][0]',        \n",
            "                                                                  'conv4_block6_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
            "                                                                  'conv5_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['post_relu[0][0]']              \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " my_predictions (Dense)         (None, 28)           57372       ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,622,172\n",
            "Trainable params: 23,576,732\n",
            "Non-trainable params: 45,440\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ModelCheckpoint callback - save best weights\n",
        "estopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
        "checkpoint = ModelCheckpoint(filepath='/content/drive/MyDrive/Mestrado/Experimentos/exp2-KTD/exp2-pynb/model_resnet50v2_rdn.weights.best.hdf5', save_best_only=True, verbose=0)\n",
        "history = ResNet50_model.fit(x_train1, y_train, epochs=100, batch_size=16, verbose=1, shuffle=True, validation_split=0.1, callbacks=[checkpoint, estopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysurod4VoUZ4",
        "outputId": "cae895e5-ef8d-4e41-e585-06bd43623d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "189/189 [==============================] - 47s 213ms/step - loss: 1.5654 - accuracy: 0.5093 - val_loss: 16.3921 - val_accuracy: 0.0387\n",
            "Epoch 2/100\n",
            "189/189 [==============================] - 37s 195ms/step - loss: 0.4502 - accuracy: 0.8578 - val_loss: 12.2461 - val_accuracy: 0.0774\n",
            "Epoch 3/100\n",
            "189/189 [==============================] - 38s 199ms/step - loss: 0.2841 - accuracy: 0.9041 - val_loss: 3.7168 - val_accuracy: 0.3839\n",
            "Epoch 4/100\n",
            "189/189 [==============================] - 37s 194ms/step - loss: 0.1986 - accuracy: 0.9388 - val_loss: 0.4878 - val_accuracy: 0.8393\n",
            "Epoch 5/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.1319 - accuracy: 0.9570 - val_loss: 0.7338 - val_accuracy: 0.7708\n",
            "Epoch 6/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.1050 - accuracy: 0.9656 - val_loss: 0.6473 - val_accuracy: 0.7708\n",
            "Epoch 7/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.1171 - accuracy: 0.9656 - val_loss: 0.8031 - val_accuracy: 0.7917\n",
            "Epoch 8/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0930 - accuracy: 0.9722 - val_loss: 1.0387 - val_accuracy: 0.7768\n",
            "Epoch 9/100\n",
            "189/189 [==============================] - 37s 199ms/step - loss: 0.0612 - accuracy: 0.9815 - val_loss: 0.2875 - val_accuracy: 0.9345\n",
            "Epoch 10/100\n",
            "189/189 [==============================] - 37s 197ms/step - loss: 0.0350 - accuracy: 0.9917 - val_loss: 0.0615 - val_accuracy: 0.9792\n",
            "Epoch 11/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0489 - accuracy: 0.9845 - val_loss: 0.9887 - val_accuracy: 0.7857\n",
            "Epoch 12/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0533 - accuracy: 0.9848 - val_loss: 0.4334 - val_accuracy: 0.8690\n",
            "Epoch 13/100\n",
            "189/189 [==============================] - 31s 163ms/step - loss: 0.0625 - accuracy: 0.9808 - val_loss: 1.6298 - val_accuracy: 0.6905\n",
            "Epoch 14/100\n",
            "189/189 [==============================] - 31s 163ms/step - loss: 0.0695 - accuracy: 0.9775 - val_loss: 0.2338 - val_accuracy: 0.9167\n",
            "Epoch 15/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0313 - accuracy: 0.9914 - val_loss: 0.7792 - val_accuracy: 0.7946\n",
            "Epoch 16/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0364 - accuracy: 0.9894 - val_loss: 0.1843 - val_accuracy: 0.9405\n",
            "Epoch 17/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0398 - accuracy: 0.9868 - val_loss: 0.7243 - val_accuracy: 0.8244\n",
            "Epoch 18/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0539 - accuracy: 0.9825 - val_loss: 0.1498 - val_accuracy: 0.9464\n",
            "Epoch 19/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0648 - accuracy: 0.9782 - val_loss: 2.1998 - val_accuracy: 0.6131\n",
            "Epoch 20/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0672 - accuracy: 0.9778 - val_loss: 0.2965 - val_accuracy: 0.8958\n",
            "Epoch 21/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0280 - accuracy: 0.9907 - val_loss: 0.0692 - val_accuracy: 0.9821\n",
            "Epoch 22/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0268 - accuracy: 0.9897 - val_loss: 0.2389 - val_accuracy: 0.9196\n",
            "Epoch 23/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0445 - accuracy: 0.9828 - val_loss: 0.3586 - val_accuracy: 0.8958\n",
            "Epoch 24/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0421 - accuracy: 0.9871 - val_loss: 0.2890 - val_accuracy: 0.9286\n",
            "Epoch 25/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0435 - accuracy: 0.9854 - val_loss: 0.6778 - val_accuracy: 0.8333\n",
            "Epoch 26/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0409 - accuracy: 0.9884 - val_loss: 0.2141 - val_accuracy: 0.9524\n",
            "Epoch 27/100\n",
            "189/189 [==============================] - 38s 201ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0183 - accuracy: 0.9960 - val_loss: 0.2974 - val_accuracy: 0.9196\n",
            "Epoch 29/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0276 - accuracy: 0.9921 - val_loss: 0.5374 - val_accuracy: 0.8601\n",
            "Epoch 30/100\n",
            "189/189 [==============================] - 31s 163ms/step - loss: 0.0638 - accuracy: 0.9798 - val_loss: 2.3310 - val_accuracy: 0.6161\n",
            "Epoch 31/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0373 - accuracy: 0.9868 - val_loss: 0.0529 - val_accuracy: 0.9792\n",
            "Epoch 32/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.3861 - val_accuracy: 0.9018\n",
            "Epoch 33/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0228 - accuracy: 0.9937 - val_loss: 0.0743 - val_accuracy: 0.9732\n",
            "Epoch 34/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.1912 - val_accuracy: 0.9494\n",
            "Epoch 35/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0667 - val_accuracy: 0.9732\n",
            "Epoch 36/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0385 - accuracy: 0.9884 - val_loss: 1.3819 - val_accuracy: 0.7411\n",
            "Epoch 37/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0727 - accuracy: 0.9752 - val_loss: 0.4565 - val_accuracy: 0.8720\n",
            "Epoch 38/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.0415 - val_accuracy: 0.9762\n",
            "Epoch 39/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0083 - accuracy: 0.9990 - val_loss: 0.0213 - val_accuracy: 0.9911\n",
            "Epoch 40/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.0652 - val_accuracy: 0.9583\n",
            "Epoch 41/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0240 - accuracy: 0.9934 - val_loss: 0.3124 - val_accuracy: 0.9226\n",
            "Epoch 42/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0202 - accuracy: 0.9960 - val_loss: 2.6118 - val_accuracy: 0.6845\n",
            "Epoch 43/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 0.0535 - val_accuracy: 0.9792\n",
            "Epoch 44/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.0310 - val_accuracy: 0.9881\n",
            "Epoch 45/100\n",
            "189/189 [==============================] - 31s 163ms/step - loss: 0.0237 - accuracy: 0.9927 - val_loss: 1.3210 - val_accuracy: 0.7619\n",
            "Epoch 46/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0439 - accuracy: 0.9894 - val_loss: 0.2677 - val_accuracy: 0.9345\n",
            "Epoch 47/100\n",
            "189/189 [==============================] - 31s 164ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0657 - val_accuracy: 0.9851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(121), plt.plot(history.history['loss'], label='loss')\n",
        "plt.subplot(121), plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Época', fontsize=12), plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Evolução da curva de perda')\n",
        "plt.legend()\n",
        "plt.subplot(122), plt.plot(history.history['accuracy'], label = 'accuracy', color='green')\n",
        "plt.subplot(122), plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Época', fontsize=12), plt.ylabel('Acc', fontsize=12)\n",
        "plt.title('Evolução da curva de acurácia')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "sty7pveTxV3Z",
        "outputId": "d42d1d4f-2bcc-437d-90d8-63b06e159c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet50_model.load_weights('/content/drive/MyDrive/Mestrado/Experimentos/exp2-KTD/exp2-pynb/model_resnet50v2_rdn.weights.best.hdf5')"
      ],
      "metadata": {
        "id": "i0sAvGcun_ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TEST ACC ###\n",
        "scores = ResNet50_model.evaluate(x_test1, y_test)\n",
        "print('\\n%s : %.2f%%' % (ResNet50_model.metrics_names[1], scores[1] * 100))"
      ],
      "metadata": {
        "id": "oxSpFAKlxVJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce2ca86-7769-4abd-fc19-50eeb80135c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 4s 90ms/step - loss: 0.0721 - accuracy: 0.9777\n",
            "\n",
            "accuracy : 97.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### VARYING DATA SIZE"
      ],
      "metadata": {
        "id": "rEA5dhJfHw-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc=[]\n",
        "percents = [0.1, 0.25, 0.5, 0.75, 1.00]\n",
        "for i in percents:\n",
        "  tf.keras.backend.clear_session()\n",
        "  print(\"Execucao {}\".format(i))\n",
        "  tf.random.set_seed(s) #s\n",
        "  opt = Adam(learning_rate=0.0001)\n",
        "  def split(x,y, test_size):\n",
        "    x_train, x_test2, y_train, y_test2 = train_test_split(np.asarray(x), np.asarray(y), test_size=test_size, stratify=y)\n",
        "    del x_train\n",
        "    del y_train\n",
        "    return x_test2, y_test2\n",
        "  def non_pre_trained_model(input_shape, n_classes, optimizer, fine_tune=0):\n",
        "    \"\"\"\n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training.\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze. \n",
        "               0 = all pretrained layers will freeze during training\n",
        "    \"\"\"\n",
        "    \n",
        "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
        "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
        "    resnet50_model = ResNet50V2(include_top=True,\n",
        "                     weights=None, \n",
        "                     input_shape=input_shape)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
        "    # depending on the size of the fine-tuning parameter.\n",
        "    '''\n",
        "    if fine_tune > 0:\n",
        "        for layer in resnet50_model.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in resnet50_model.layers:\n",
        "            layer.trainable = False\n",
        "    '''\n",
        "    for layer in resnet50_model.layers:\n",
        "      layer.trainable = True\n",
        "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
        "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
        "    top_model = resnet50_model.layers[-2].output\n",
        "    #top_model = Flatten(name=\"flatten\")(top_model)\n",
        "    #top_model = Dense(4096, activation='relu')(top_model)\n",
        "    #top_model = Dense(128, activation='relu')(top_model)\n",
        "    #top_model = Dropout(0.25)(top_model)\n",
        "    output_layer = Dense(n_classes, activation='softmax', name='my_predictions')(top_model)\n",
        "    \n",
        "    # Group the convolutional base and new output into a Model object.\n",
        "    model = Model(inputs=resnet50_model.input, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "  ResNet50_model = non_pre_trained_model(input_shape=(224,224,3), n_classes=28, optimizer=opt)\n",
        "  if i !=1.00:\n",
        "    print('<1')\n",
        "    input_half, y_train_half = split(x_train1,y_train, i)\n",
        "  else:\n",
        "    print(\"Dataset Completo\")\n",
        "    input_half,y_train_half = x_train1,y_train\n",
        "  # ModelCheckpoint callback - save best weights\n",
        "  estopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
        "  #checkpoint = ModelCheckpoint(filepath='/content/drive/MyDrive/Mestrado/Experimentos/exp2-KTD/exp2-pynb/model_efficientnetv2s_pt.weights.best.hdf5', save_best_only=True, verbose=0)\n",
        "  history = ResNet50_model.fit(input_half, y_train_half, epochs=100, batch_size=16, verbose=0, shuffle=True, validation_split=0.1, callbacks=[estopping]) #checkpoint, \n",
        "  scores = ResNet50_model.evaluate(x_test1, y_test)\n",
        "  print('\\n%s : %.2f%%' % (ResNet50_model.metrics_names[1], scores[1] * 100))\n",
        "  acc.append(scores[1])\n",
        "  del input_half\n",
        "  del y_train_half\n",
        "  del ResNet50_model\n",
        "np.savetxt('/content/drive/MyDrive/Mestrado/Experimentos/exp2-KTD/exp2-pynb/acc_exp2_asoc_ResNetV2.txt', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hTU7KDRHzKL",
        "outputId": "1ea50513-3630-4bed-aab6-4e3da174ed33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execucao 0.1\n",
            "<1\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 7.5580 - accuracy: 0.0509\n",
            "\n",
            "accuracy : 5.09%\n",
            "Execucao 0.25\n",
            "<1\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.3659 - accuracy: 0.8830\n",
            "\n",
            "accuracy : 88.30%\n",
            "Execucao 0.5\n",
            "<1\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.8199 - accuracy: 0.7625\n",
            "\n",
            "accuracy : 76.25%\n",
            "Execucao 0.75\n",
            "<1\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0705 - accuracy: 0.9795\n",
            "\n",
            "accuracy : 97.95%\n",
            "Execucao 1.0\n",
            "Dataset Completo\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0466 - accuracy: 0.9848\n",
            "\n",
            "accuracy : 98.48%\n"
          ]
        }
      ]
    }
  ]
}