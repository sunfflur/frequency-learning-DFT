{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OhBI2fC_sXT_",
        "Bu99OidX-urG",
        "8XfRzO2W769C",
        "PyK2jV9QElu7"
      ],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPnAZg6ij2StuljzBxewbAE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunfflur/frequency-learning/blob/master/Exp_02_ViT-b/16/32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0GGocS93vIn"
      },
      "source": [
        "### Experiment - ViTs\n",
        "\n",
        "`Author:` [sunfflur](https://github.com/sunfflur)\n",
        "\n",
        "> This experiment considers the 28 classes from Kylberg Texture Dataset being classified by ViT-b/32 and ViT-b/16 through transfer learning.\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup"
      ],
      "metadata": {
        "id": "OhBI2fC_sXT_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9Pmr-27rySj",
        "outputId": "6fcc4ac5-6811-46de-f764-d2a52d130ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "pip install -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vit-keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XjJJeeMFF0X",
        "outputId": "07b1638f-cb4b-45c7-bfb7-15ae63bd5f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting vit-keras\n",
            "  Downloading vit_keras-0.1.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from vit-keras) (1.10.1)\n",
            "Collecting validators (from vit-keras)\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->vit-keras) (1.22.4)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators->vit-keras) (4.4.2)\n",
            "Building wheels for collected packages: validators\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19579 sha256=65d746c1cf492659d3205535d80f0a5f7dfd5c9b0b82383d8baf4f112420d8fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/ed/dd/d3a556ad245ef9dc570c6bcd2f22886d17b0b408dd3bbb9ac3\n",
            "Successfully built validators\n",
            "Installing collected packages: validators, vit-keras\n",
            "Successfully installed validators-0.20.0 vit-keras-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "from vit_keras import vit, utils\n",
        "from tensorflow.keras.layers import Layer, Dense, Conv1D, Dropout, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn"
      ],
      "metadata": {
        "id": "ksYTWCPdsSZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea1ba8fc-2e45-4161-9123-fad69890be3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Drive mount"
      ],
      "metadata": {
        "id": "Bu99OidX-urG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!sudo apt-get update -qq 2>&1 > /dev/null\n",
        "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "!google-drive-ocamlfuse"
      ],
      "metadata": {
        "id": "je242-LYOKFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aae7f33-83f4-4f26-fff1-b3c52ccf037e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "/usr/bin/xdg-open: 869: www-browser: not found\n",
            "/usr/bin/xdg-open: 869: links2: not found\n",
            "/usr/bin/xdg-open: 869: elinks: not found\n",
            "/usr/bin/xdg-open: 869: links: not found\n",
            "/usr/bin/xdg-open: 869: lynx: not found\n",
            "/usr/bin/xdg-open: 869: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=zSryXQ4GGiyAkvGbYaUM50AF3S5izoS3cwpmff4W3Dk'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/bin/sh: 1: open: not found\n",
            "Cannot retrieve auth tokens.\n",
            "Failure(\"Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=zSryXQ4GGiyAkvGbYaUM50AF3S5izoS3cwpmff4W3Dk\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -qq w3m # to act as web browser \n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBjc7IqP3wqU",
        "outputId": "9c1503b6-84e5-4d53-fb1f-96940683b392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package w3m.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 122536 files and directories currently installed.)\n",
            "Preparing to unpack .../w3m_0.5.3-37ubuntu0.1_amd64.deb ...\n",
            "Unpacking w3m (0.5.3-37ubuntu0.1) ...\n",
            "Setting up w3m (0.5.3-37ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "/content\n",
            "/content/drive\n",
            "/content\n",
            "/\n",
            "Access token retrieved correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare the data"
      ],
      "metadata": {
        "id": "lmdzUaB4s7O6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Kylberg Texture Dataset"
      ],
      "metadata": {
        "id": "5DGiJKdgn65A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 28\n",
        "input_shape = (384, 384, 1)\n",
        "\n",
        "### data loading ### \n",
        "path_train = '/content/drive/MyDrive/Mestrado/Datasets/kylberg-dataset/kylberg_train.npy'\n",
        "path_ytrain = '/content/drive/MyDrive/Mestrado/Datasets/kylberg-dataset/kylberg_y_train.npy'\n",
        "path_test = '/content/drive/MyDrive/Mestrado/Datasets/kylberg-dataset/kylberg_test.npy'\n",
        "path_ytest = '/content/drive/MyDrive/Mestrado/Datasets/kylberg-dataset/kylberg_y_test.npy'\n",
        "\n",
        "x_train, x_test = np.load(path_train), np.load(path_test)\n",
        "y_train, y_test = np.load(path_ytrain), np.load(path_ytest)\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
        "\n",
        "# adjust dimension and change from array to tensor\n",
        "new_shape = (384,384)\n",
        "x_train, x_test = np.asarray(tf.image.resize(x_train, new_shape)), np.asarray(tf.image.resize(x_test, new_shape))\n",
        "y_train, y_test = y_train.reshape(y_train.shape[0], 1), y_test.reshape(y_test.shape[0], 1)\n",
        "y_train, y_test = tf.stack(to_categorical(y_train)), tf.stack(to_categorical(y_test))"
      ],
      "metadata": {
        "id": "XKXpOGfZs9T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ds_split(ds, ds_size, train_split=0.9, val_split=0.1, shuffle=False, shuffle_size=None):\n",
        "    assert (train_split + val_split) == 1\n",
        "    \n",
        "    if shuffle:\n",
        "        # Specify seed to always have the same split distribution between runs\n",
        "        ds = ds.shuffle(shuffle_size, seed=11)\n",
        "    \n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "    \n",
        "    train_ds = ds.take(train_size)    \n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    #test_ds = ds.skip(train_size).skip(val_size)\n",
        "    \n",
        "    return train_ds, val_ds"
      ],
      "metadata": {
        "id": "sEMKCmT_QS-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dstrain = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "dstest = tf.data.Dataset.from_tensor_slices((x_test,y_test))"
      ],
      "metadata": {
        "id": "wh2H3Fv2MYPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_x, x_val_x = ds_split(dstrain, 3360)"
      ],
      "metadata": {
        "id": "IB79qVQYQaV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 4\n",
        "x_train1 = x_train_x.batch(bs, drop_remainder=True).map(lambda x,y: (tf.image.grayscale_to_rgb(x), y)).prefetch(tf.data.AUTOTUNE).cache() #\n",
        "x_val1 = x_val_x.batch(bs, drop_remainder=True).map(lambda x,y: (tf.image.grayscale_to_rgb(x), y)).prefetch(tf.data.AUTOTUNE).cache()\n",
        "x_test1 = dstest.batch(bs, drop_remainder=True).map(lambda x,y: (tf.image.grayscale_to_rgb(x), y)).cache().prefetch(tf.data.AUTOTUNE) "
      ],
      "metadata": {
        "id": "f63RcUeTMhFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transfer learning - VITb16 - 384x384"
      ],
      "metadata": {
        "id": "PyK2jV9QElu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_trained_model(input_shape, n_classes, optimizer, fine_tune=0):\n",
        "    \"\"\"\n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training.\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze. \n",
        "               0 = all pretrained layers will freeze during training\n",
        "    \"\"\"\n",
        "    \n",
        "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
        "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
        "    classes = utils.get_imagenet_classes()\n",
        "    vit_model = vit.vit_b16(\n",
        "        image_size=input_shape[0],\n",
        "        activation='sigmoid',\n",
        "        pretrained=True,\n",
        "        include_top=True,\n",
        "        pretrained_top=True)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
        "    # depending on the size of the fine-tuning parameter.\n",
        "    \n",
        "    if fine_tune > 0:\n",
        "        for layer in vit_model.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in vit_model.layers:\n",
        "            layer.trainable = False\n",
        "    '''\n",
        "    # Turn all the layers trainable.\n",
        "\n",
        "    for layer in densenet_model.layers:\n",
        "      layer.trainable = True\n",
        "    '''\n",
        "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
        "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
        "    top_model = vit_model.layers[-2].output\n",
        "    #top_model = Flatten(name=\"flatten\")(top_model)\n",
        "    #top_model = Dense(4096, activation='relu')(top_model)\n",
        "    #top_model = Dense(128, activation='relu')(top_model)\n",
        "    #top_model = Dropout(0.25)(top_model)\n",
        "    output_layer = Dense(n_classes, activation='softmax', name='my_predictions')(top_model)\n",
        "    \n",
        "    # Group the convolutional base and new output into a Model object.\n",
        "    model = Model(inputs=vit_model.input, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "fbR9QSwXH2zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(11) #s\n",
        "\n",
        "### inverse time decay  ###\n",
        "inversetime_decay = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  initial_learning_rate = 0.001, #0.01 - opt2 lr=0.001\n",
        "  decay_steps = 3360/bs,\n",
        "  decay_rate = 0.005) \n",
        "opt = Adam(learning_rate=inversetime_decay)\n",
        "vit16_model = pre_trained_model(input_shape=(384,384,3), n_classes=28, optimizer=opt)"
      ],
      "metadata": {
        "id": "bKi3HtZ0IlvM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec160978-3220-45c0-f011-2c2e10da52fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/faustomorales/vit-keras/releases/download/dl/ViT-B_16_imagenet21k+imagenet2012.npz\n",
            "347502902/347502902 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#new test chaning image size\n",
        "# ModelCheckpoint callback - save best weights #time: 5h1min31s\n",
        "estopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
        "checkpoint = ModelCheckpoint(filepath='/content/drive/MyDrive/Mestrado/Experimentos/exp-ktd/exp-ktd-pynb/model_VITb16_pt.weights.best.hdf5', save_best_only=True, verbose=0)\n",
        "history = vit16_model.fit(x_train1, validation_data= x_val1, epochs=100, verbose=1, callbacks=[checkpoint,estopping], shuffle=True) #,batch_size=16, validation_split=0.1, shuffle=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58a53746-5250-4e6e-e74e-9848062fd2df",
        "id": "8d9uPC-vOOUi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "756/756 [==============================] - 198s 252ms/step - loss: 2.1389 - accuracy: 0.4375 - val_loss: 1.2045 - val_accuracy: 0.7083\n",
            "Epoch 2/100\n",
            "756/756 [==============================] - 182s 241ms/step - loss: 1.1806 - accuracy: 0.6786 - val_loss: 0.8456 - val_accuracy: 0.7738\n",
            "Epoch 3/100\n",
            "756/756 [==============================] - 183s 242ms/step - loss: 0.9026 - accuracy: 0.7464 - val_loss: 0.6710 - val_accuracy: 0.8333\n",
            "Epoch 4/100\n",
            "756/756 [==============================] - 181s 240ms/step - loss: 0.7656 - accuracy: 0.7811 - val_loss: 0.5520 - val_accuracy: 0.8423\n",
            "Epoch 5/100\n",
            "756/756 [==============================] - 182s 241ms/step - loss: 0.6584 - accuracy: 0.8062 - val_loss: 0.4822 - val_accuracy: 0.8780\n",
            "Epoch 6/100\n",
            "756/756 [==============================] - 187s 247ms/step - loss: 0.5970 - accuracy: 0.8234 - val_loss: 0.4536 - val_accuracy: 0.8631\n",
            "Epoch 7/100\n",
            "756/756 [==============================] - 187s 248ms/step - loss: 0.5437 - accuracy: 0.8360 - val_loss: 0.3834 - val_accuracy: 0.9345\n",
            "Epoch 8/100\n",
            "756/756 [==============================] - 188s 248ms/step - loss: 0.4979 - accuracy: 0.8426 - val_loss: 0.3522 - val_accuracy: 0.9315\n",
            "Epoch 9/100\n",
            "756/756 [==============================] - 188s 249ms/step - loss: 0.4777 - accuracy: 0.8485 - val_loss: 0.3410 - val_accuracy: 0.9315\n",
            "Epoch 10/100\n",
            "756/756 [==============================] - 189s 250ms/step - loss: 0.4515 - accuracy: 0.8532 - val_loss: 0.3076 - val_accuracy: 0.9464\n",
            "Epoch 11/100\n",
            "756/756 [==============================] - 176s 233ms/step - loss: 0.4423 - accuracy: 0.8562 - val_loss: 0.3208 - val_accuracy: 0.9196\n",
            "Epoch 12/100\n",
            "756/756 [==============================] - 186s 247ms/step - loss: 0.4208 - accuracy: 0.8631 - val_loss: 0.2915 - val_accuracy: 0.9167\n",
            "Epoch 13/100\n",
            "756/756 [==============================] - 187s 247ms/step - loss: 0.4127 - accuracy: 0.8624 - val_loss: 0.2791 - val_accuracy: 0.9286\n",
            "Epoch 14/100\n",
            "756/756 [==============================] - 188s 249ms/step - loss: 0.3873 - accuracy: 0.8730 - val_loss: 0.2607 - val_accuracy: 0.9315\n",
            "Epoch 15/100\n",
            "756/756 [==============================] - 176s 233ms/step - loss: 0.3680 - accuracy: 0.8743 - val_loss: 0.2722 - val_accuracy: 0.9375\n",
            "Epoch 16/100\n",
            "756/756 [==============================] - 186s 246ms/step - loss: 0.3692 - accuracy: 0.8786 - val_loss: 0.2426 - val_accuracy: 0.9435\n",
            "Epoch 17/100\n",
            "756/756 [==============================] - 187s 247ms/step - loss: 0.3589 - accuracy: 0.8783 - val_loss: 0.2338 - val_accuracy: 0.9494\n",
            "Epoch 18/100\n",
            "756/756 [==============================] - 188s 248ms/step - loss: 0.3478 - accuracy: 0.8836 - val_loss: 0.2082 - val_accuracy: 0.9524\n",
            "Epoch 19/100\n",
            "756/756 [==============================] - 176s 232ms/step - loss: 0.3418 - accuracy: 0.8869 - val_loss: 0.2093 - val_accuracy: 0.9554\n",
            "Epoch 20/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.3380 - accuracy: 0.8889 - val_loss: 0.2303 - val_accuracy: 0.9554\n",
            "Epoch 21/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.3129 - accuracy: 0.8988 - val_loss: 0.2110 - val_accuracy: 0.9375\n",
            "Epoch 22/100\n",
            "756/756 [==============================] - 176s 233ms/step - loss: 0.3090 - accuracy: 0.8972 - val_loss: 0.2523 - val_accuracy: 0.9196\n",
            "Epoch 23/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.3284 - accuracy: 0.8859 - val_loss: 0.2528 - val_accuracy: 0.9048\n",
            "Epoch 24/100\n",
            "756/756 [==============================] - 188s 248ms/step - loss: 0.2987 - accuracy: 0.9028 - val_loss: 0.1757 - val_accuracy: 0.9583\n",
            "Epoch 25/100\n",
            "756/756 [==============================] - 176s 233ms/step - loss: 0.2917 - accuracy: 0.9001 - val_loss: 0.2016 - val_accuracy: 0.9435\n",
            "Epoch 26/100\n",
            "756/756 [==============================] - 184s 244ms/step - loss: 0.3002 - accuracy: 0.8975 - val_loss: 0.1745 - val_accuracy: 0.9643\n",
            "Epoch 27/100\n",
            "756/756 [==============================] - 176s 233ms/step - loss: 0.2860 - accuracy: 0.8972 - val_loss: 0.1765 - val_accuracy: 0.9613\n",
            "Epoch 28/100\n",
            "756/756 [==============================] - 175s 231ms/step - loss: 0.2904 - accuracy: 0.9031 - val_loss: 0.1833 - val_accuracy: 0.9583\n",
            "Epoch 29/100\n",
            "756/756 [==============================] - 184s 243ms/step - loss: 0.2746 - accuracy: 0.9084 - val_loss: 0.1654 - val_accuracy: 0.9702\n",
            "Epoch 30/100\n",
            "756/756 [==============================] - 185s 244ms/step - loss: 0.2868 - accuracy: 0.9024 - val_loss: 0.1597 - val_accuracy: 0.9643\n",
            "Epoch 31/100\n",
            "756/756 [==============================] - 176s 232ms/step - loss: 0.2825 - accuracy: 0.9031 - val_loss: 0.1768 - val_accuracy: 0.9583\n",
            "Epoch 32/100\n",
            "756/756 [==============================] - 175s 231ms/step - loss: 0.2605 - accuracy: 0.9137 - val_loss: 0.1597 - val_accuracy: 0.9554\n",
            "Epoch 33/100\n",
            "756/756 [==============================] - 176s 232ms/step - loss: 0.2717 - accuracy: 0.9048 - val_loss: 0.1721 - val_accuracy: 0.9494\n",
            "Epoch 34/100\n",
            "756/756 [==============================] - 187s 247ms/step - loss: 0.2713 - accuracy: 0.9097 - val_loss: 0.1441 - val_accuracy: 0.9613\n",
            "Epoch 35/100\n",
            "756/756 [==============================] - 186s 246ms/step - loss: 0.2818 - accuracy: 0.9048 - val_loss: 0.1416 - val_accuracy: 0.9643\n",
            "Epoch 36/100\n",
            "756/756 [==============================] - 186s 246ms/step - loss: 0.2638 - accuracy: 0.9101 - val_loss: 0.1335 - val_accuracy: 0.9702\n",
            "Epoch 37/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2602 - accuracy: 0.9107 - val_loss: 0.1525 - val_accuracy: 0.9613\n",
            "Epoch 38/100\n",
            "756/756 [==============================] - 174s 231ms/step - loss: 0.2670 - accuracy: 0.9081 - val_loss: 0.1662 - val_accuracy: 0.9494\n",
            "Epoch 39/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2529 - accuracy: 0.9130 - val_loss: 0.1564 - val_accuracy: 0.9554\n",
            "Epoch 40/100\n",
            "756/756 [==============================] - 175s 231ms/step - loss: 0.2410 - accuracy: 0.9193 - val_loss: 0.1344 - val_accuracy: 0.9673\n",
            "Epoch 41/100\n",
            "756/756 [==============================] - 175s 231ms/step - loss: 0.2535 - accuracy: 0.9101 - val_loss: 0.1497 - val_accuracy: 0.9673\n",
            "Epoch 42/100\n",
            "756/756 [==============================] - 174s 231ms/step - loss: 0.2489 - accuracy: 0.9124 - val_loss: 0.1443 - val_accuracy: 0.9613\n",
            "Epoch 43/100\n",
            "756/756 [==============================] - 174s 231ms/step - loss: 0.2471 - accuracy: 0.9150 - val_loss: 0.1619 - val_accuracy: 0.9613\n",
            "Epoch 44/100\n",
            "756/756 [==============================] - 175s 231ms/step - loss: 0.2447 - accuracy: 0.9147 - val_loss: 0.1487 - val_accuracy: 0.9643\n",
            "Epoch 45/100\n",
            "756/756 [==============================] - 174s 231ms/step - loss: 0.2417 - accuracy: 0.9216 - val_loss: 0.1395 - val_accuracy: 0.9643\n",
            "Epoch 46/100\n",
            "756/756 [==============================] - 175s 231ms/step - loss: 0.2487 - accuracy: 0.9137 - val_loss: 0.1536 - val_accuracy: 0.9524\n",
            "Epoch 47/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2312 - accuracy: 0.9220 - val_loss: 0.1762 - val_accuracy: 0.9554\n",
            "Epoch 48/100\n",
            "756/756 [==============================] - 188s 249ms/step - loss: 0.2463 - accuracy: 0.9160 - val_loss: 0.1250 - val_accuracy: 0.9702\n",
            "Epoch 49/100\n",
            "756/756 [==============================] - 176s 232ms/step - loss: 0.2367 - accuracy: 0.9180 - val_loss: 0.1283 - val_accuracy: 0.9673\n",
            "Epoch 50/100\n",
            "756/756 [==============================] - 174s 230ms/step - loss: 0.2258 - accuracy: 0.9243 - val_loss: 0.1291 - val_accuracy: 0.9643\n",
            "Epoch 51/100\n",
            "756/756 [==============================] - 174s 230ms/step - loss: 0.2460 - accuracy: 0.9153 - val_loss: 0.1325 - val_accuracy: 0.9673\n",
            "Epoch 52/100\n",
            "756/756 [==============================] - 174s 231ms/step - loss: 0.2440 - accuracy: 0.9120 - val_loss: 0.1682 - val_accuracy: 0.9554\n",
            "Epoch 53/100\n",
            "756/756 [==============================] - 174s 231ms/step - loss: 0.2336 - accuracy: 0.9140 - val_loss: 0.1371 - val_accuracy: 0.9702\n",
            "Epoch 54/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2365 - accuracy: 0.9203 - val_loss: 0.1265 - val_accuracy: 0.9702\n",
            "Epoch 55/100\n",
            "756/756 [==============================] - 183s 242ms/step - loss: 0.2244 - accuracy: 0.9233 - val_loss: 0.1233 - val_accuracy: 0.9673\n",
            "Epoch 56/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2135 - accuracy: 0.9263 - val_loss: 0.1389 - val_accuracy: 0.9554\n",
            "Epoch 57/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2393 - accuracy: 0.9157 - val_loss: 0.1485 - val_accuracy: 0.9554\n",
            "Epoch 58/100\n",
            "756/756 [==============================] - 176s 232ms/step - loss: 0.2293 - accuracy: 0.9187 - val_loss: 0.1248 - val_accuracy: 0.9673\n",
            "Epoch 59/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2271 - accuracy: 0.9183 - val_loss: 0.1257 - val_accuracy: 0.9613\n",
            "Epoch 60/100\n",
            "756/756 [==============================] - 189s 249ms/step - loss: 0.2125 - accuracy: 0.9239 - val_loss: 0.1166 - val_accuracy: 0.9673\n",
            "Epoch 61/100\n",
            "756/756 [==============================] - 176s 233ms/step - loss: 0.2450 - accuracy: 0.9183 - val_loss: 0.1221 - val_accuracy: 0.9643\n",
            "Epoch 62/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2102 - accuracy: 0.9272 - val_loss: 0.1239 - val_accuracy: 0.9643\n",
            "Epoch 63/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2164 - accuracy: 0.9213 - val_loss: 0.1303 - val_accuracy: 0.9643\n",
            "Epoch 64/100\n",
            "756/756 [==============================] - 176s 232ms/step - loss: 0.2145 - accuracy: 0.9286 - val_loss: 0.1417 - val_accuracy: 0.9643\n",
            "Epoch 65/100\n",
            "756/756 [==============================] - 185s 245ms/step - loss: 0.2217 - accuracy: 0.9210 - val_loss: 0.1136 - val_accuracy: 0.9673\n",
            "Epoch 66/100\n",
            "756/756 [==============================] - 176s 233ms/step - loss: 0.2302 - accuracy: 0.9167 - val_loss: 0.1329 - val_accuracy: 0.9643\n",
            "Epoch 67/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2103 - accuracy: 0.9220 - val_loss: 0.1275 - val_accuracy: 0.9613\n",
            "Epoch 68/100\n",
            "756/756 [==============================] - 184s 244ms/step - loss: 0.2097 - accuracy: 0.9249 - val_loss: 0.1084 - val_accuracy: 0.9762\n",
            "Epoch 69/100\n",
            "756/756 [==============================] - 176s 232ms/step - loss: 0.2199 - accuracy: 0.9216 - val_loss: 0.1123 - val_accuracy: 0.9702\n",
            "Epoch 70/100\n",
            "756/756 [==============================] - 174s 231ms/step - loss: 0.2158 - accuracy: 0.9183 - val_loss: 0.1441 - val_accuracy: 0.9524\n",
            "Epoch 71/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2228 - accuracy: 0.9157 - val_loss: 0.1166 - val_accuracy: 0.9732\n",
            "Epoch 72/100\n",
            "756/756 [==============================] - 187s 247ms/step - loss: 0.1944 - accuracy: 0.9335 - val_loss: 0.1069 - val_accuracy: 0.9702\n",
            "Epoch 73/100\n",
            "756/756 [==============================] - 176s 233ms/step - loss: 0.2313 - accuracy: 0.9190 - val_loss: 0.1212 - val_accuracy: 0.9732\n",
            "Epoch 74/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2041 - accuracy: 0.9276 - val_loss: 0.1245 - val_accuracy: 0.9702\n",
            "Epoch 75/100\n",
            "756/756 [==============================] - 175s 231ms/step - loss: 0.2049 - accuracy: 0.9239 - val_loss: 0.1087 - val_accuracy: 0.9732\n",
            "Epoch 76/100\n",
            "756/756 [==============================] - 186s 246ms/step - loss: 0.1968 - accuracy: 0.9299 - val_loss: 0.0984 - val_accuracy: 0.9792\n",
            "Epoch 77/100\n",
            "756/756 [==============================] - 176s 232ms/step - loss: 0.2064 - accuracy: 0.9286 - val_loss: 0.1041 - val_accuracy: 0.9702\n",
            "Epoch 78/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2055 - accuracy: 0.9342 - val_loss: 0.1235 - val_accuracy: 0.9613\n",
            "Epoch 79/100\n",
            "756/756 [==============================] - 174s 231ms/step - loss: 0.2059 - accuracy: 0.9266 - val_loss: 0.1089 - val_accuracy: 0.9643\n",
            "Epoch 80/100\n",
            "756/756 [==============================] - 174s 231ms/step - loss: 0.1997 - accuracy: 0.9282 - val_loss: 0.1086 - val_accuracy: 0.9673\n",
            "Epoch 81/100\n",
            "756/756 [==============================] - 175s 231ms/step - loss: 0.2094 - accuracy: 0.9190 - val_loss: 0.1072 - val_accuracy: 0.9732\n",
            "Epoch 82/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2134 - accuracy: 0.9236 - val_loss: 0.1197 - val_accuracy: 0.9673\n",
            "Epoch 83/100\n",
            "756/756 [==============================] - 176s 232ms/step - loss: 0.2091 - accuracy: 0.9269 - val_loss: 0.1243 - val_accuracy: 0.9643\n",
            "Epoch 84/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2027 - accuracy: 0.9276 - val_loss: 0.1016 - val_accuracy: 0.9702\n",
            "Epoch 85/100\n",
            "756/756 [==============================] - 186s 246ms/step - loss: 0.1891 - accuracy: 0.9339 - val_loss: 0.0974 - val_accuracy: 0.9762\n",
            "Epoch 86/100\n",
            "756/756 [==============================] - 176s 233ms/step - loss: 0.2097 - accuracy: 0.9263 - val_loss: 0.0981 - val_accuracy: 0.9702\n",
            "Epoch 87/100\n",
            "756/756 [==============================] - 176s 232ms/step - loss: 0.1908 - accuracy: 0.9306 - val_loss: 0.1077 - val_accuracy: 0.9702\n",
            "Epoch 88/100\n",
            "756/756 [==============================] - 175s 231ms/step - loss: 0.1951 - accuracy: 0.9289 - val_loss: 0.1160 - val_accuracy: 0.9702\n",
            "Epoch 89/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.2038 - accuracy: 0.9292 - val_loss: 0.1214 - val_accuracy: 0.9613\n",
            "Epoch 90/100\n",
            "756/756 [==============================] - 175s 231ms/step - loss: 0.2061 - accuracy: 0.9246 - val_loss: 0.1137 - val_accuracy: 0.9643\n",
            "Epoch 91/100\n",
            "756/756 [==============================] - 175s 231ms/step - loss: 0.2094 - accuracy: 0.9233 - val_loss: 0.0976 - val_accuracy: 0.9702\n",
            "Epoch 92/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.1971 - accuracy: 0.9296 - val_loss: 0.1157 - val_accuracy: 0.9643\n",
            "Epoch 93/100\n",
            "756/756 [==============================] - 176s 232ms/step - loss: 0.1963 - accuracy: 0.9319 - val_loss: 0.1135 - val_accuracy: 0.9702\n",
            "Epoch 94/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.1962 - accuracy: 0.9315 - val_loss: 0.1141 - val_accuracy: 0.9673\n",
            "Epoch 95/100\n",
            "756/756 [==============================] - 175s 231ms/step - loss: 0.1972 - accuracy: 0.9306 - val_loss: 0.1120 - val_accuracy: 0.9613\n",
            "Epoch 96/100\n",
            "756/756 [==============================] - 187s 248ms/step - loss: 0.2090 - accuracy: 0.9272 - val_loss: 0.0881 - val_accuracy: 0.9762\n",
            "Epoch 97/100\n",
            "756/756 [==============================] - 176s 233ms/step - loss: 0.1944 - accuracy: 0.9365 - val_loss: 0.1128 - val_accuracy: 0.9613\n",
            "Epoch 98/100\n",
            "756/756 [==============================] - 175s 232ms/step - loss: 0.1925 - accuracy: 0.9358 - val_loss: 0.0947 - val_accuracy: 0.9732\n",
            "Epoch 99/100\n",
            "756/756 [==============================] - 176s 233ms/step - loss: 0.1854 - accuracy: 0.9329 - val_loss: 0.1149 - val_accuracy: 0.9673\n",
            "Epoch 100/100\n",
            "756/756 [==============================] - 175s 231ms/step - loss: 0.1958 - accuracy: 0.9302 - val_loss: 0.1058 - val_accuracy: 0.9673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vit16_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIBq0ITlTnq4",
        "outputId": "197e79cf-dcc4-4bd2-c345-b135ea0eab16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 384, 384, 3)]     0         \n",
            "                                                                 \n",
            " embedding (Conv2D)          (None, 24, 24, 768)       590592    \n",
            "                                                                 \n",
            " reshape_4 (Reshape)         (None, 576, 768)          0         \n",
            "                                                                 \n",
            " class_token (ClassToken)    (None, 577, 768)          768       \n",
            "                                                                 \n",
            " Transformer/posembed_input   (None, 577, 768)         443136    \n",
            " (AddPositionEmbs)                                               \n",
            "                                                                 \n",
            " Transformer/encoderblock_0   ((None, 577, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_1   ((None, 577, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_2   ((None, 577, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_3   ((None, 577, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_4   ((None, 577, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_5   ((None, 577, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_6   ((None, 577, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_7   ((None, 577, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_8   ((None, 577, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_9   ((None, 577, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_10  ((None, 577, 768),       7087872   \n",
            "  (TransformerBlock)          (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_11  ((None, 577, 768),       7087872   \n",
            "  (TransformerBlock)          (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoder_norm (L  (None, 577, 768)         1536      \n",
            " ayerNormalization)                                              \n",
            "                                                                 \n",
            " ExtractToken (Lambda)       (None, 768)               0         \n",
            "                                                                 \n",
            " my_predictions (Dense)      (None, 28)                21532     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 86,112,028\n",
            "Trainable params: 21,532\n",
            "Non-trainable params: 86,090,496\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = vit16_model.evaluate(x_test1)\n",
        "print('\\n%s : %.2f%%' % (vit16_model.metrics_names[1], scores[1] * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPQx1gnIT0Hv",
        "outputId": "66cd70a5-3cca-4474-e9f4-6e48ce08b309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280/280 [==============================] - 57s 204ms/step - loss: 0.1055 - accuracy: 0.9679\n",
            "\n",
            "accuracy : 96.79%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transfer Learning - VITb16 - 224X224"
      ],
      "metadata": {
        "id": "Q8WO3JlcTccm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_trained_model(input_shape, n_classes, optimizer, fine_tune=0):\n",
        "    \"\"\"\n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training.\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze. \n",
        "               0 = all pretrained layers will freeze during training\n",
        "    \"\"\"\n",
        "    \n",
        "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
        "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
        "    classes = utils.get_imagenet_classes()\n",
        "    vit_model = vit.vit_b16(\n",
        "        image_size=input_shape[0],\n",
        "        activation='sigmoid',\n",
        "        pretrained=True,\n",
        "        include_top=True,\n",
        "        pretrained_top=True)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
        "    # depending on the size of the fine-tuning parameter.\n",
        "    \n",
        "    if fine_tune > 0:\n",
        "        for layer in vit_model.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in vit_model.layers:\n",
        "            layer.trainable = False\n",
        "    '''\n",
        "    # Turn all the layers trainable.\n",
        "\n",
        "    for layer in densenet_model.layers:\n",
        "      layer.trainable = True\n",
        "    '''\n",
        "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
        "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
        "    top_model = vit_model.layers[-2].output\n",
        "    #top_model = Flatten(name=\"flatten\")(top_model)\n",
        "    #top_model = Dense(4096, activation='relu')(top_model)\n",
        "    #top_model = Dense(128, activation='relu')(top_model)\n",
        "    #top_model = Dropout(0.25)(top_model)\n",
        "    output_layer = Dense(n_classes, activation='softmax', name='my_predictions')(top_model)\n",
        "    \n",
        "    # Group the convolutional base and new output into a Model object.\n",
        "    model = Model(inputs=vit_model.input, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "qqBsUrMw_BkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(11) #s\n",
        "\n",
        "### inverse time decay  ###\n",
        "inversetime_decay = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  initial_learning_rate = 0.001, #0.01 - opt2 lr=0.001\n",
        "  decay_steps = 3360/bs,\n",
        "  decay_rate = 0.005) \n",
        "opt = Adam(learning_rate=inversetime_decay)\n",
        "vit16_model = pre_trained_model(input_shape=(224,224,3), n_classes=28, optimizer=opt)"
      ],
      "metadata": {
        "id": "pDeSVgEs_BYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ModelCheckpoint callback - save best weights #1h3min2s\n",
        "estopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
        "checkpoint = ModelCheckpoint(filepath='/content/drive/MyDrive/Mestrado/Experimentos/exp-ktd/exp-ktd-pynb/model_VITb16_224pt.weights.best.hdf5', save_best_only=True, verbose=0)\n",
        "history = vit16_model.fit(x_train1, validation_data= x_val1, epochs=100, verbose=1, callbacks=[checkpoint,estopping], shuffle=True) #,batch_size=16, validation_split=0.1, shuffle=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qNSjSfzKt3u",
        "outputId": "1f5c5762-87ac-4ea6-b420-b00232344910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "756/756 [==============================] - 87s 93ms/step - loss: 2.1257 - accuracy: 0.4461 - val_loss: 1.2247 - val_accuracy: 0.6756\n",
            "Epoch 2/100\n",
            "756/756 [==============================] - 59s 78ms/step - loss: 1.1736 - accuracy: 0.6723 - val_loss: 0.8572 - val_accuracy: 0.7649\n",
            "Epoch 3/100\n",
            "756/756 [==============================] - 61s 81ms/step - loss: 0.8905 - accuracy: 0.7560 - val_loss: 0.6993 - val_accuracy: 0.8304\n",
            "Epoch 4/100\n",
            "756/756 [==============================] - 70s 93ms/step - loss: 0.7640 - accuracy: 0.7794 - val_loss: 0.5858 - val_accuracy: 0.8452\n",
            "Epoch 5/100\n",
            "756/756 [==============================] - 61s 81ms/step - loss: 0.6761 - accuracy: 0.7996 - val_loss: 0.5194 - val_accuracy: 0.8750\n",
            "Epoch 6/100\n",
            "756/756 [==============================] - 64s 84ms/step - loss: 0.5936 - accuracy: 0.8218 - val_loss: 0.4859 - val_accuracy: 0.8542\n",
            "Epoch 7/100\n",
            "756/756 [==============================] - 61s 81ms/step - loss: 0.5444 - accuracy: 0.8323 - val_loss: 0.4426 - val_accuracy: 0.8601\n",
            "Epoch 8/100\n",
            "756/756 [==============================] - 62s 81ms/step - loss: 0.5146 - accuracy: 0.8439 - val_loss: 0.4038 - val_accuracy: 0.8869\n",
            "Epoch 9/100\n",
            "756/756 [==============================] - 64s 85ms/step - loss: 0.4787 - accuracy: 0.8525 - val_loss: 0.3941 - val_accuracy: 0.8839\n",
            "Epoch 10/100\n",
            "756/756 [==============================] - 62s 83ms/step - loss: 0.4565 - accuracy: 0.8568 - val_loss: 0.3761 - val_accuracy: 0.8869\n",
            "Epoch 11/100\n",
            "756/756 [==============================] - 63s 84ms/step - loss: 0.4311 - accuracy: 0.8621 - val_loss: 0.3615 - val_accuracy: 0.8720\n",
            "Epoch 12/100\n",
            "756/756 [==============================] - 62s 82ms/step - loss: 0.4159 - accuracy: 0.8651 - val_loss: 0.3596 - val_accuracy: 0.8810\n",
            "Epoch 13/100\n",
            "756/756 [==============================] - 61s 81ms/step - loss: 0.4026 - accuracy: 0.8700 - val_loss: 0.3344 - val_accuracy: 0.8869\n",
            "Epoch 14/100\n",
            "756/756 [==============================] - 53s 70ms/step - loss: 0.3874 - accuracy: 0.8724 - val_loss: 0.3471 - val_accuracy: 0.8601\n",
            "Epoch 15/100\n",
            "756/756 [==============================] - 61s 80ms/step - loss: 0.3734 - accuracy: 0.8806 - val_loss: 0.3126 - val_accuracy: 0.8899\n",
            "Epoch 16/100\n",
            "756/756 [==============================] - 62s 82ms/step - loss: 0.3612 - accuracy: 0.8776 - val_loss: 0.3062 - val_accuracy: 0.8810\n",
            "Epoch 17/100\n",
            "756/756 [==============================] - 63s 84ms/step - loss: 0.3559 - accuracy: 0.8743 - val_loss: 0.2975 - val_accuracy: 0.8988\n",
            "Epoch 18/100\n",
            "756/756 [==============================] - 52s 68ms/step - loss: 0.3454 - accuracy: 0.8849 - val_loss: 0.3109 - val_accuracy: 0.8929\n",
            "Epoch 19/100\n",
            "756/756 [==============================] - 61s 81ms/step - loss: 0.3328 - accuracy: 0.8942 - val_loss: 0.2871 - val_accuracy: 0.8899\n",
            "Epoch 20/100\n",
            "756/756 [==============================] - 64s 85ms/step - loss: 0.3364 - accuracy: 0.8876 - val_loss: 0.2850 - val_accuracy: 0.8988\n",
            "Epoch 21/100\n",
            "756/756 [==============================] - 52s 68ms/step - loss: 0.3324 - accuracy: 0.8853 - val_loss: 0.3228 - val_accuracy: 0.8810\n",
            "Epoch 22/100\n",
            "756/756 [==============================] - 51s 67ms/step - loss: 0.3218 - accuracy: 0.8849 - val_loss: 0.2887 - val_accuracy: 0.8869\n",
            "Epoch 23/100\n",
            "756/756 [==============================] - 62s 83ms/step - loss: 0.3110 - accuracy: 0.8965 - val_loss: 0.2578 - val_accuracy: 0.9167\n",
            "Epoch 24/100\n",
            "756/756 [==============================] - 53s 70ms/step - loss: 0.2950 - accuracy: 0.9064 - val_loss: 0.2658 - val_accuracy: 0.8899\n",
            "Epoch 25/100\n",
            "756/756 [==============================] - 60s 80ms/step - loss: 0.3100 - accuracy: 0.8909 - val_loss: 0.2576 - val_accuracy: 0.9167\n",
            "Epoch 26/100\n",
            "756/756 [==============================] - 53s 71ms/step - loss: 0.2890 - accuracy: 0.8981 - val_loss: 0.2951 - val_accuracy: 0.8839\n",
            "Epoch 27/100\n",
            "756/756 [==============================] - 51s 67ms/step - loss: 0.2889 - accuracy: 0.9048 - val_loss: 0.3049 - val_accuracy: 0.8750\n",
            "Epoch 28/100\n",
            "756/756 [==============================] - 51s 68ms/step - loss: 0.2772 - accuracy: 0.9101 - val_loss: 0.2593 - val_accuracy: 0.9018\n",
            "Epoch 29/100\n",
            "756/756 [==============================] - 51s 67ms/step - loss: 0.2837 - accuracy: 0.9011 - val_loss: 0.2593 - val_accuracy: 0.9048\n",
            "Epoch 30/100\n",
            "756/756 [==============================] - 66s 87ms/step - loss: 0.2798 - accuracy: 0.9011 - val_loss: 0.2532 - val_accuracy: 0.8958\n",
            "Epoch 31/100\n",
            "756/756 [==============================] - 52s 69ms/step - loss: 0.2723 - accuracy: 0.9127 - val_loss: 0.2538 - val_accuracy: 0.9077\n",
            "Epoch 32/100\n",
            "756/756 [==============================] - 51s 67ms/step - loss: 0.2720 - accuracy: 0.9087 - val_loss: 0.2661 - val_accuracy: 0.8958\n",
            "Epoch 33/100\n",
            "756/756 [==============================] - 52s 69ms/step - loss: 0.2746 - accuracy: 0.9048 - val_loss: 0.2545 - val_accuracy: 0.9048\n",
            "Epoch 34/100\n",
            "756/756 [==============================] - 61s 81ms/step - loss: 0.2636 - accuracy: 0.9110 - val_loss: 0.2513 - val_accuracy: 0.9018\n",
            "Epoch 35/100\n",
            "756/756 [==============================] - 64s 84ms/step - loss: 0.2705 - accuracy: 0.9107 - val_loss: 0.2479 - val_accuracy: 0.9077\n",
            "Epoch 36/100\n",
            "756/756 [==============================] - 52s 69ms/step - loss: 0.2566 - accuracy: 0.9120 - val_loss: 0.2490 - val_accuracy: 0.9107\n",
            "Epoch 37/100\n",
            "756/756 [==============================] - 51s 68ms/step - loss: 0.2600 - accuracy: 0.9110 - val_loss: 0.2516 - val_accuracy: 0.9048\n",
            "Epoch 38/100\n",
            "756/756 [==============================] - 61s 81ms/step - loss: 0.2592 - accuracy: 0.9120 - val_loss: 0.2281 - val_accuracy: 0.9048\n",
            "Epoch 39/100\n",
            "756/756 [==============================] - 53s 70ms/step - loss: 0.2593 - accuracy: 0.9134 - val_loss: 0.2655 - val_accuracy: 0.8899\n",
            "Epoch 40/100\n",
            "756/756 [==============================] - 51s 67ms/step - loss: 0.2576 - accuracy: 0.9071 - val_loss: 0.2727 - val_accuracy: 0.8899\n",
            "Epoch 41/100\n",
            "756/756 [==============================] - 63s 83ms/step - loss: 0.2419 - accuracy: 0.9193 - val_loss: 0.2219 - val_accuracy: 0.9107\n",
            "Epoch 42/100\n",
            "756/756 [==============================] - 52s 69ms/step - loss: 0.2441 - accuracy: 0.9144 - val_loss: 0.2733 - val_accuracy: 0.8899\n",
            "Epoch 43/100\n",
            "756/756 [==============================] - 51s 67ms/step - loss: 0.2388 - accuracy: 0.9183 - val_loss: 0.2416 - val_accuracy: 0.9107\n",
            "Epoch 44/100\n",
            "756/756 [==============================] - 52s 69ms/step - loss: 0.2371 - accuracy: 0.9180 - val_loss: 0.2772 - val_accuracy: 0.8929\n",
            "Epoch 45/100\n",
            "756/756 [==============================] - 51s 67ms/step - loss: 0.2509 - accuracy: 0.9114 - val_loss: 0.2429 - val_accuracy: 0.9077\n",
            "Epoch 46/100\n",
            "756/756 [==============================] - 51s 68ms/step - loss: 0.2499 - accuracy: 0.9087 - val_loss: 0.2414 - val_accuracy: 0.8958\n",
            "Epoch 47/100\n",
            "756/756 [==============================] - 51s 67ms/step - loss: 0.2312 - accuracy: 0.9177 - val_loss: 0.2334 - val_accuracy: 0.9018\n",
            "Epoch 48/100\n",
            "756/756 [==============================] - 52s 69ms/step - loss: 0.2324 - accuracy: 0.9210 - val_loss: 0.2233 - val_accuracy: 0.9107\n",
            "Epoch 49/100\n",
            "756/756 [==============================] - 51s 67ms/step - loss: 0.2461 - accuracy: 0.9107 - val_loss: 0.2233 - val_accuracy: 0.9137\n",
            "Epoch 50/100\n",
            "756/756 [==============================] - 52s 69ms/step - loss: 0.2414 - accuracy: 0.9144 - val_loss: 0.2253 - val_accuracy: 0.9077\n",
            "Epoch 51/100\n",
            "756/756 [==============================] - 51s 67ms/step - loss: 0.2374 - accuracy: 0.9223 - val_loss: 0.2465 - val_accuracy: 0.8958\n",
            "Epoch 52/100\n",
            "756/756 [==============================] - 52s 68ms/step - loss: 0.2326 - accuracy: 0.9153 - val_loss: 0.2363 - val_accuracy: 0.8988\n",
            "Epoch 53/100\n",
            "756/756 [==============================] - 51s 67ms/step - loss: 0.2230 - accuracy: 0.9200 - val_loss: 0.2314 - val_accuracy: 0.9137\n",
            "Epoch 54/100\n",
            "756/756 [==============================] - 52s 69ms/step - loss: 0.2285 - accuracy: 0.9180 - val_loss: 0.2382 - val_accuracy: 0.9107\n",
            "Epoch 55/100\n",
            "756/756 [==============================] - 51s 67ms/step - loss: 0.2373 - accuracy: 0.9134 - val_loss: 0.2326 - val_accuracy: 0.8958\n",
            "Epoch 56/100\n",
            "756/756 [==============================] - 53s 70ms/step - loss: 0.2257 - accuracy: 0.9200 - val_loss: 0.2234 - val_accuracy: 0.9167\n",
            "Epoch 57/100\n",
            "756/756 [==============================] - 51s 67ms/step - loss: 0.2334 - accuracy: 0.9180 - val_loss: 0.2387 - val_accuracy: 0.9137\n",
            "Epoch 58/100\n",
            "756/756 [==============================] - 52s 69ms/step - loss: 0.2227 - accuracy: 0.9236 - val_loss: 0.2435 - val_accuracy: 0.9137\n",
            "Epoch 59/100\n",
            "756/756 [==============================] - 51s 67ms/step - loss: 0.2166 - accuracy: 0.9299 - val_loss: 0.2497 - val_accuracy: 0.9018\n",
            "Epoch 60/100\n",
            "756/756 [==============================] - 52s 69ms/step - loss: 0.2125 - accuracy: 0.9263 - val_loss: 0.2623 - val_accuracy: 0.8958\n",
            "Epoch 61/100\n",
            "756/756 [==============================] - 51s 67ms/step - loss: 0.2156 - accuracy: 0.9203 - val_loss: 0.2366 - val_accuracy: 0.8958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vit16_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otfag10VG6C9",
        "outputId": "97f86a5d-4a04-43ca-ef67-3335ea81785b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " embedding (Conv2D)          (None, 14, 14, 768)       590592    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 196, 768)          0         \n",
            "                                                                 \n",
            " class_token (ClassToken)    (None, 197, 768)          768       \n",
            "                                                                 \n",
            " Transformer/posembed_input   (None, 197, 768)         151296    \n",
            " (AddPositionEmbs)                                               \n",
            "                                                                 \n",
            " Transformer/encoderblock_0   ((None, 197, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_1   ((None, 197, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_2   ((None, 197, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_3   ((None, 197, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_4   ((None, 197, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_5   ((None, 197, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_6   ((None, 197, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_7   ((None, 197, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_8   ((None, 197, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_9   ((None, 197, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_10  ((None, 197, 768),       7087872   \n",
            "  (TransformerBlock)          (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_11  ((None, 197, 768),       7087872   \n",
            "  (TransformerBlock)          (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoder_norm (L  (None, 197, 768)         1536      \n",
            " ayerNormalization)                                              \n",
            "                                                                 \n",
            " ExtractToken (Lambda)       (None, 768)               0         \n",
            "                                                                 \n",
            " my_predictions (Dense)      (None, 28)                21532     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,820,188\n",
            "Trainable params: 21,532\n",
            "Non-trainable params: 85,798,656\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vit16_model.load_weights('/content/drive/MyDrive/Mestrado/Experimentos/exp-ktd/exp-ktd-pynb/model_VITb16_pt224.weights.best.hdf5')"
      ],
      "metadata": {
        "id": "gsiPHe95B_8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = vit16_model.evaluate(x_test1)\n",
        "print('\\n%s : %.2f%%' % (vit16_model.metrics_names[1], scores[1] * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtVyS7HC2xza",
        "outputId": "003edbe0-2939-4e73-9ff0-964b6f2abf6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280/280 [==============================] - 15s 54ms/step - loss: 0.2439 - accuracy: 0.9107\n",
            "\n",
            "accuracy : 91.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transfer learning - VITb32 - 384x384"
      ],
      "metadata": {
        "id": "d9t_U_dfDDKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_trained_model(input_shape, n_classes, optimizer, fine_tune=0):\n",
        "    \"\"\"\n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training.\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze. \n",
        "               0 = all pretrained layers will freeze during training\n",
        "    \"\"\"\n",
        "    \n",
        "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
        "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
        "    classes = utils.get_imagenet_classes()\n",
        "    vit_model = vit.vit_b32(\n",
        "        image_size=input_shape[0],\n",
        "        activation='sigmoid',\n",
        "        pretrained=True,\n",
        "        include_top=True,\n",
        "        pretrained_top=True)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
        "    # depending on the size of the fine-tuning parameter.\n",
        "    \n",
        "    if fine_tune > 0:\n",
        "        for layer in vit_model.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in vit_model.layers:\n",
        "            layer.trainable = False\n",
        "    '''\n",
        "    # Turn all the layers trainable.\n",
        "\n",
        "    for layer in densenet_model.layers:\n",
        "      layer.trainable = True\n",
        "    '''\n",
        "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
        "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
        "    top_model = vit_model.layers[-2].output\n",
        "    #top_model = Flatten(name=\"flatten\")(top_model)\n",
        "    #top_model = Dense(4096, activation='relu')(top_model)\n",
        "    #top_model = Dense(128, activation='relu')(top_model)\n",
        "    #top_model = Dropout(0.25)(top_model)\n",
        "    output_layer = Dense(n_classes, activation='softmax', name='my_predictions')(top_model)\n",
        "    \n",
        "    # Group the convolutional base and new output into a Model object.\n",
        "    model = Model(inputs=vit_model.input, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "QQ3j5CsVDDK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(11) #s\n",
        "\n",
        "### inverse time decay  ###\n",
        "inversetime_decay = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  initial_learning_rate = 0.001, #0.01 - opt2 lr=0.001\n",
        "  decay_steps = 3360/bs,\n",
        "  decay_rate = 0.005)\n",
        "#opt = Adam(learning_rate=inversetime_decay) \n",
        "opt = Adam(learning_rate=inversetime_decay)\n",
        "vitb32_model = pre_trained_model(input_shape=(384,384,3), n_classes=28, optimizer=opt)"
      ],
      "metadata": {
        "id": "3sZHd1tWDDK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ModelCheckpoint callback - save best weights #1h13min57s\n",
        "estopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
        "checkpoint = ModelCheckpoint(filepath='/content/drive/MyDrive/Mestrado/Experimentos/exp-ktd/exp-ktd-pynb/model_VITb32_pt.weights.best.hdf5', save_best_only=True, verbose=0)\n",
        "history = vitb32_model.fit(x_train1, validation_data= x_val1, epochs=100, verbose=1, callbacks=[checkpoint,estopping], shuffle=True) #,batch_size=16, validation_split=0.1, shuffle=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8f181b-05df-4266-8f01-a3f6cc201bc7",
        "id": "wg9q-O9wDDK1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "756/756 [==============================] - 66s 77ms/step - loss: 2.5748 - accuracy: 0.3016 - val_loss: 1.7449 - val_accuracy: 0.4762\n",
            "Epoch 2/100\n",
            "756/756 [==============================] - 48s 63ms/step - loss: 1.6668 - accuracy: 0.5351 - val_loss: 1.3047 - val_accuracy: 0.6161\n",
            "Epoch 3/100\n",
            "756/756 [==============================] - 48s 64ms/step - loss: 1.3617 - accuracy: 0.5989 - val_loss: 1.1103 - val_accuracy: 0.6786\n",
            "Epoch 4/100\n",
            "756/756 [==============================] - 47s 62ms/step - loss: 1.1829 - accuracy: 0.6508 - val_loss: 0.9501 - val_accuracy: 0.7321\n",
            "Epoch 5/100\n",
            "756/756 [==============================] - 48s 63ms/step - loss: 1.0644 - accuracy: 0.6776 - val_loss: 0.8851 - val_accuracy: 0.7232\n",
            "Epoch 6/100\n",
            "756/756 [==============================] - 47s 62ms/step - loss: 0.9833 - accuracy: 0.6938 - val_loss: 0.8220 - val_accuracy: 0.7292\n",
            "Epoch 7/100\n",
            "756/756 [==============================] - 47s 62ms/step - loss: 0.9166 - accuracy: 0.7136 - val_loss: 0.7574 - val_accuracy: 0.7619\n",
            "Epoch 8/100\n",
            "756/756 [==============================] - 47s 62ms/step - loss: 0.8810 - accuracy: 0.7235 - val_loss: 0.7173 - val_accuracy: 0.7470\n",
            "Epoch 9/100\n",
            "756/756 [==============================] - 47s 63ms/step - loss: 0.8310 - accuracy: 0.7321 - val_loss: 0.7029 - val_accuracy: 0.7560\n",
            "Epoch 10/100\n",
            "756/756 [==============================] - 48s 63ms/step - loss: 0.8043 - accuracy: 0.7401 - val_loss: 0.6705 - val_accuracy: 0.7798\n",
            "Epoch 11/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.7718 - accuracy: 0.7507 - val_loss: 0.6753 - val_accuracy: 0.7649\n",
            "Epoch 12/100\n",
            "756/756 [==============================] - 47s 63ms/step - loss: 0.7350 - accuracy: 0.7566 - val_loss: 0.6114 - val_accuracy: 0.7917\n",
            "Epoch 13/100\n",
            "756/756 [==============================] - 41s 54ms/step - loss: 0.7223 - accuracy: 0.7573 - val_loss: 0.6131 - val_accuracy: 0.7976\n",
            "Epoch 14/100\n",
            "756/756 [==============================] - 47s 62ms/step - loss: 0.7101 - accuracy: 0.7629 - val_loss: 0.5798 - val_accuracy: 0.8065\n",
            "Epoch 15/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.6958 - accuracy: 0.7679 - val_loss: 0.6347 - val_accuracy: 0.7440\n",
            "Epoch 16/100\n",
            "756/756 [==============================] - 47s 62ms/step - loss: 0.6703 - accuracy: 0.7708 - val_loss: 0.5368 - val_accuracy: 0.8065\n",
            "Epoch 17/100\n",
            "756/756 [==============================] - 41s 54ms/step - loss: 0.6719 - accuracy: 0.7695 - val_loss: 0.5383 - val_accuracy: 0.8304\n",
            "Epoch 18/100\n",
            "756/756 [==============================] - 40s 52ms/step - loss: 0.6360 - accuracy: 0.7870 - val_loss: 0.5925 - val_accuracy: 0.7917\n",
            "Epoch 19/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.6311 - accuracy: 0.7788 - val_loss: 0.5400 - val_accuracy: 0.8065\n",
            "Epoch 20/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.6245 - accuracy: 0.7834 - val_loss: 0.5662 - val_accuracy: 0.7798\n",
            "Epoch 21/100\n",
            "756/756 [==============================] - 46s 61ms/step - loss: 0.6285 - accuracy: 0.7834 - val_loss: 0.5188 - val_accuracy: 0.8333\n",
            "Epoch 22/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.6208 - accuracy: 0.7857 - val_loss: 0.5282 - val_accuracy: 0.8006\n",
            "Epoch 23/100\n",
            "756/756 [==============================] - 48s 63ms/step - loss: 0.5966 - accuracy: 0.7950 - val_loss: 0.5033 - val_accuracy: 0.8244\n",
            "Epoch 24/100\n",
            "756/756 [==============================] - 47s 62ms/step - loss: 0.5873 - accuracy: 0.7960 - val_loss: 0.4777 - val_accuracy: 0.8304\n",
            "Epoch 25/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.5801 - accuracy: 0.8026 - val_loss: 0.4865 - val_accuracy: 0.8214\n",
            "Epoch 26/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.5940 - accuracy: 0.7917 - val_loss: 0.5002 - val_accuracy: 0.8333\n",
            "Epoch 27/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.5719 - accuracy: 0.7993 - val_loss: 0.4980 - val_accuracy: 0.8214\n",
            "Epoch 28/100\n",
            "756/756 [==============================] - 46s 61ms/step - loss: 0.5556 - accuracy: 0.8069 - val_loss: 0.4742 - val_accuracy: 0.8452\n",
            "Epoch 29/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.5556 - accuracy: 0.8085 - val_loss: 0.4826 - val_accuracy: 0.8333\n",
            "Epoch 30/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.5532 - accuracy: 0.8003 - val_loss: 0.4776 - val_accuracy: 0.8363\n",
            "Epoch 31/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.5404 - accuracy: 0.8185 - val_loss: 0.5004 - val_accuracy: 0.8155\n",
            "Epoch 32/100\n",
            "756/756 [==============================] - 47s 62ms/step - loss: 0.5610 - accuracy: 0.7996 - val_loss: 0.4433 - val_accuracy: 0.8482\n",
            "Epoch 33/100\n",
            "756/756 [==============================] - 41s 54ms/step - loss: 0.5335 - accuracy: 0.8142 - val_loss: 0.4476 - val_accuracy: 0.8304\n",
            "Epoch 34/100\n",
            "756/756 [==============================] - 40s 52ms/step - loss: 0.5350 - accuracy: 0.8105 - val_loss: 0.4854 - val_accuracy: 0.8214\n",
            "Epoch 35/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.5176 - accuracy: 0.8204 - val_loss: 0.4548 - val_accuracy: 0.8363\n",
            "Epoch 36/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.5218 - accuracy: 0.8194 - val_loss: 0.4484 - val_accuracy: 0.8363\n",
            "Epoch 37/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.5081 - accuracy: 0.8148 - val_loss: 0.4856 - val_accuracy: 0.8006\n",
            "Epoch 38/100\n",
            "756/756 [==============================] - 40s 52ms/step - loss: 0.5307 - accuracy: 0.8171 - val_loss: 0.4921 - val_accuracy: 0.8185\n",
            "Epoch 39/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.5245 - accuracy: 0.8102 - val_loss: 0.4866 - val_accuracy: 0.8065\n",
            "Epoch 40/100\n",
            "756/756 [==============================] - 47s 62ms/step - loss: 0.5154 - accuracy: 0.8185 - val_loss: 0.4357 - val_accuracy: 0.8363\n",
            "Epoch 41/100\n",
            "756/756 [==============================] - 41s 54ms/step - loss: 0.5126 - accuracy: 0.8221 - val_loss: 0.4484 - val_accuracy: 0.8214\n",
            "Epoch 42/100\n",
            "756/756 [==============================] - 41s 54ms/step - loss: 0.5068 - accuracy: 0.8237 - val_loss: 0.4885 - val_accuracy: 0.8155\n",
            "Epoch 43/100\n",
            "756/756 [==============================] - 47s 63ms/step - loss: 0.4906 - accuracy: 0.8224 - val_loss: 0.4183 - val_accuracy: 0.8452\n",
            "Epoch 44/100\n",
            "756/756 [==============================] - 48s 63ms/step - loss: 0.5055 - accuracy: 0.8181 - val_loss: 0.4082 - val_accuracy: 0.8482\n",
            "Epoch 45/100\n",
            "756/756 [==============================] - 47s 62ms/step - loss: 0.4913 - accuracy: 0.8204 - val_loss: 0.3862 - val_accuracy: 0.8601\n",
            "Epoch 46/100\n",
            "756/756 [==============================] - 41s 54ms/step - loss: 0.4908 - accuracy: 0.8218 - val_loss: 0.4043 - val_accuracy: 0.8571\n",
            "Epoch 47/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4927 - accuracy: 0.8234 - val_loss: 0.3952 - val_accuracy: 0.8661\n",
            "Epoch 48/100\n",
            "756/756 [==============================] - 40s 52ms/step - loss: 0.4777 - accuracy: 0.8290 - val_loss: 0.4333 - val_accuracy: 0.8333\n",
            "Epoch 49/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4943 - accuracy: 0.8241 - val_loss: 0.3971 - val_accuracy: 0.8571\n",
            "Epoch 50/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4831 - accuracy: 0.8254 - val_loss: 0.4061 - val_accuracy: 0.8482\n",
            "Epoch 51/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4961 - accuracy: 0.8274 - val_loss: 0.4295 - val_accuracy: 0.8363\n",
            "Epoch 52/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4754 - accuracy: 0.8327 - val_loss: 0.4324 - val_accuracy: 0.8452\n",
            "Epoch 53/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4636 - accuracy: 0.8271 - val_loss: 0.4191 - val_accuracy: 0.8363\n",
            "Epoch 54/100\n",
            "756/756 [==============================] - 40s 52ms/step - loss: 0.4907 - accuracy: 0.8211 - val_loss: 0.4084 - val_accuracy: 0.8423\n",
            "Epoch 55/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4660 - accuracy: 0.8307 - val_loss: 0.4220 - val_accuracy: 0.8333\n",
            "Epoch 56/100\n",
            "756/756 [==============================] - 40s 52ms/step - loss: 0.4831 - accuracy: 0.8231 - val_loss: 0.4211 - val_accuracy: 0.8452\n",
            "Epoch 57/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4541 - accuracy: 0.8347 - val_loss: 0.4291 - val_accuracy: 0.8185\n",
            "Epoch 58/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4577 - accuracy: 0.8406 - val_loss: 0.3906 - val_accuracy: 0.8601\n",
            "Epoch 59/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4625 - accuracy: 0.8343 - val_loss: 0.4012 - val_accuracy: 0.8571\n",
            "Epoch 60/100\n",
            "756/756 [==============================] - 40s 52ms/step - loss: 0.4585 - accuracy: 0.8356 - val_loss: 0.4027 - val_accuracy: 0.8482\n",
            "Epoch 61/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4378 - accuracy: 0.8433 - val_loss: 0.3873 - val_accuracy: 0.8601\n",
            "Epoch 62/100\n",
            "756/756 [==============================] - 47s 63ms/step - loss: 0.4640 - accuracy: 0.8363 - val_loss: 0.3812 - val_accuracy: 0.8661\n",
            "Epoch 63/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4478 - accuracy: 0.8383 - val_loss: 0.4023 - val_accuracy: 0.8512\n",
            "Epoch 64/100\n",
            "756/756 [==============================] - 40s 52ms/step - loss: 0.4570 - accuracy: 0.8390 - val_loss: 0.3939 - val_accuracy: 0.8631\n",
            "Epoch 65/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4587 - accuracy: 0.8376 - val_loss: 0.3882 - val_accuracy: 0.8690\n",
            "Epoch 66/100\n",
            "756/756 [==============================] - 40s 52ms/step - loss: 0.4480 - accuracy: 0.8360 - val_loss: 0.4131 - val_accuracy: 0.8304\n",
            "Epoch 67/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4550 - accuracy: 0.8436 - val_loss: 0.4078 - val_accuracy: 0.8482\n",
            "Epoch 68/100\n",
            "756/756 [==============================] - 47s 62ms/step - loss: 0.4504 - accuracy: 0.8403 - val_loss: 0.3693 - val_accuracy: 0.8631\n",
            "Epoch 69/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4551 - accuracy: 0.8356 - val_loss: 0.3785 - val_accuracy: 0.8601\n",
            "Epoch 70/100\n",
            "756/756 [==============================] - 47s 62ms/step - loss: 0.4742 - accuracy: 0.8261 - val_loss: 0.3636 - val_accuracy: 0.8720\n",
            "Epoch 71/100\n",
            "756/756 [==============================] - 41s 54ms/step - loss: 0.4471 - accuracy: 0.8370 - val_loss: 0.4087 - val_accuracy: 0.8363\n",
            "Epoch 72/100\n",
            "756/756 [==============================] - 39s 52ms/step - loss: 0.4319 - accuracy: 0.8515 - val_loss: 0.3636 - val_accuracy: 0.8571\n",
            "Epoch 73/100\n",
            "756/756 [==============================] - 49s 65ms/step - loss: 0.4692 - accuracy: 0.8313 - val_loss: 0.3552 - val_accuracy: 0.8750\n",
            "Epoch 74/100\n",
            "756/756 [==============================] - 47s 62ms/step - loss: 0.4291 - accuracy: 0.8489 - val_loss: 0.3546 - val_accuracy: 0.8839\n",
            "Epoch 75/100\n",
            "756/756 [==============================] - 41s 54ms/step - loss: 0.4451 - accuracy: 0.8393 - val_loss: 0.3675 - val_accuracy: 0.8690\n",
            "Epoch 76/100\n",
            "756/756 [==============================] - 40s 52ms/step - loss: 0.4370 - accuracy: 0.8429 - val_loss: 0.3811 - val_accuracy: 0.8631\n",
            "Epoch 77/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4651 - accuracy: 0.8257 - val_loss: 0.3791 - val_accuracy: 0.8601\n",
            "Epoch 78/100\n",
            "756/756 [==============================] - 48s 63ms/step - loss: 0.4486 - accuracy: 0.8390 - val_loss: 0.3458 - val_accuracy: 0.8839\n",
            "Epoch 79/100\n",
            "756/756 [==============================] - 41s 54ms/step - loss: 0.4511 - accuracy: 0.8390 - val_loss: 0.4028 - val_accuracy: 0.8423\n",
            "Epoch 80/100\n",
            "756/756 [==============================] - 40s 52ms/step - loss: 0.4390 - accuracy: 0.8386 - val_loss: 0.3848 - val_accuracy: 0.8482\n",
            "Epoch 81/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4636 - accuracy: 0.8376 - val_loss: 0.3916 - val_accuracy: 0.8542\n",
            "Epoch 82/100\n",
            "756/756 [==============================] - 48s 63ms/step - loss: 0.4325 - accuracy: 0.8419 - val_loss: 0.3352 - val_accuracy: 0.8839\n",
            "Epoch 83/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4356 - accuracy: 0.8446 - val_loss: 0.3832 - val_accuracy: 0.8661\n",
            "Epoch 84/100\n",
            "756/756 [==============================] - 39s 52ms/step - loss: 0.4327 - accuracy: 0.8366 - val_loss: 0.3918 - val_accuracy: 0.8601\n",
            "Epoch 85/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4312 - accuracy: 0.8476 - val_loss: 0.3553 - val_accuracy: 0.8750\n",
            "Epoch 86/100\n",
            "756/756 [==============================] - 40s 52ms/step - loss: 0.4406 - accuracy: 0.8482 - val_loss: 0.3620 - val_accuracy: 0.8750\n",
            "Epoch 87/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4257 - accuracy: 0.8509 - val_loss: 0.3522 - val_accuracy: 0.8601\n",
            "Epoch 88/100\n",
            "756/756 [==============================] - 39s 52ms/step - loss: 0.4295 - accuracy: 0.8429 - val_loss: 0.3626 - val_accuracy: 0.8690\n",
            "Epoch 89/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4493 - accuracy: 0.8383 - val_loss: 0.4185 - val_accuracy: 0.8185\n",
            "Epoch 90/100\n",
            "756/756 [==============================] - 40s 52ms/step - loss: 0.4310 - accuracy: 0.8416 - val_loss: 0.3642 - val_accuracy: 0.8690\n",
            "Epoch 91/100\n",
            "756/756 [==============================] - 48s 63ms/step - loss: 0.4135 - accuracy: 0.8512 - val_loss: 0.3343 - val_accuracy: 0.8780\n",
            "Epoch 92/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4417 - accuracy: 0.8396 - val_loss: 0.3751 - val_accuracy: 0.8571\n",
            "Epoch 93/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4185 - accuracy: 0.8449 - val_loss: 0.3485 - val_accuracy: 0.8780\n",
            "Epoch 94/100\n",
            "756/756 [==============================] - 39s 52ms/step - loss: 0.4364 - accuracy: 0.8403 - val_loss: 0.3411 - val_accuracy: 0.8690\n",
            "Epoch 95/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4312 - accuracy: 0.8373 - val_loss: 0.3492 - val_accuracy: 0.8482\n",
            "Epoch 96/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4105 - accuracy: 0.8525 - val_loss: 0.3488 - val_accuracy: 0.8750\n",
            "Epoch 97/100\n",
            "756/756 [==============================] - 40s 52ms/step - loss: 0.4402 - accuracy: 0.8363 - val_loss: 0.3746 - val_accuracy: 0.8482\n",
            "Epoch 98/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4185 - accuracy: 0.8545 - val_loss: 0.3549 - val_accuracy: 0.8720\n",
            "Epoch 99/100\n",
            "756/756 [==============================] - 40s 53ms/step - loss: 0.4243 - accuracy: 0.8449 - val_loss: 0.3892 - val_accuracy: 0.8571\n",
            "Epoch 100/100\n",
            "756/756 [==============================] - 39s 52ms/step - loss: 0.4280 - accuracy: 0.8442 - val_loss: 0.3641 - val_accuracy: 0.8571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vitb32_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a29012-f0a9-4f4e-a195-0f58c7a1ae0b",
        "id": "IrKPifIiDDK1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 384, 384, 3)]     0         \n",
            "                                                                 \n",
            " embedding (Conv2D)          (None, 12, 12, 768)       2360064   \n",
            "                                                                 \n",
            " reshape_3 (Reshape)         (None, 144, 768)          0         \n",
            "                                                                 \n",
            " class_token (ClassToken)    (None, 145, 768)          768       \n",
            "                                                                 \n",
            " Transformer/posembed_input   (None, 145, 768)         111360    \n",
            " (AddPositionEmbs)                                               \n",
            "                                                                 \n",
            " Transformer/encoderblock_0   ((None, 145, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_1   ((None, 145, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_2   ((None, 145, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_3   ((None, 145, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_4   ((None, 145, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_5   ((None, 145, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_6   ((None, 145, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_7   ((None, 145, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_8   ((None, 145, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_9   ((None, 145, 768),       7087872   \n",
            " (TransformerBlock)           (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_10  ((None, 145, 768),       7087872   \n",
            "  (TransformerBlock)          (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoderblock_11  ((None, 145, 768),       7087872   \n",
            "  (TransformerBlock)          (None, 12, None, None))            \n",
            "                                                                 \n",
            " Transformer/encoder_norm (L  (None, 145, 768)         1536      \n",
            " ayerNormalization)                                              \n",
            "                                                                 \n",
            " ExtractToken (Lambda)       (None, 768)               0         \n",
            "                                                                 \n",
            " my_predictions (Dense)      (None, 28)                21532     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,549,724\n",
            "Trainable params: 21,532\n",
            "Non-trainable params: 87,528,192\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vitb32_model.load_weights('/content/drive/MyDrive/Mestrado/Experimentos/exp-ktd/exp-ktd-pynb/model_VITb32_pt.weights.best.hdf5')"
      ],
      "metadata": {
        "id": "oCZWT9YUDDK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = vitb32_model.evaluate(x_test1)\n",
        "print('\\n%s : %.2f%%' % (vitb32_model.metrics_names[1], scores[1] * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d266704b-4d83-4199-b1d5-02bd1d123188",
        "id": "mWaIpErSDDK1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280/280 [==============================] - 13s 46ms/step - loss: 0.3392 - accuracy: 0.8786\n",
            "\n",
            "accuracy : 87.86%\n"
          ]
        }
      ]
    }
  ]
}